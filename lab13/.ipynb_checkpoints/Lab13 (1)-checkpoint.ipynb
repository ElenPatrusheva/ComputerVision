{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TC0AHGaP-1VQ"
   },
   "source": [
    "### Introduction to Computer Vision (Spring 2020)\n",
    "Instructor: Muhammad Fahim \\\\\n",
    "TA: Marcus Ebner\n",
    "\n",
    "### Acknowledgement\n",
    "This lab was maintained by Marcus\n",
    "\n",
    "# Object Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQP_dbuF-4Vb"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-228d3374d75f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install tf-nightly-gpu-2.0-preview'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import cv2\n",
    "import sys\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 10) # (w, h)\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from google.colab.patches import cv2_imshow\n",
    "import imutils\n",
    "!pip install tf-nightly-gpu-2.0-preview\n",
    "\n",
    "# For running inference on the TF-Hub module.\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# For downloading the image.\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from six.moves.urllib.request import urlopen\n",
    "from six import BytesIO\n",
    "\n",
    "# For drawing onto the image.\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bc-vO7lUBeIU"
   },
   "outputs": [],
   "source": [
    "!wget \"https://drive.google.com/uc?export=view&id=1skt6SmYqjQ_jWh4jIkpe3njILEIaS72-\" -O vid.mp4\n",
    "!wget \"https://drive.google.com/uc?id=1Ckgprba7Yd6a-nQQi9AfXvSEGsEZXpcz&authuser=0&export=download\" -O cars.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BNXrtlR_fqw"
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJNuR0Lx_eyg"
   },
   "outputs": [],
   "source": [
    "def show_in_row(list_of_images, titles = None, disable_ticks = False):\n",
    "  count = len(list_of_images)\n",
    "  for idx in range(count):\n",
    "    subplot = plt.subplot(1, count, idx+1)\n",
    "    if titles is not None:\n",
    "      subplot.set_title(titles[idx])\n",
    "      \n",
    "    img = list_of_images[idx]\n",
    "    cmap = 'gray' if (len(img.shape) == 2 or img.shape[2] == 1) else None\n",
    "    subplot.imshow(img, cmap=cmap)\n",
    "    if disable_ticks:\n",
    "      plt.xticks([]), plt.yticks([])\n",
    "  plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mSmIaS2TuWhk"
   },
   "source": [
    "Additional functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9nQ64qjt-Tn"
   },
   "outputs": [],
   "source": [
    "def detect_red(frame):\n",
    "  \"\"\"\n",
    "  Detects the largest red object in the frame and returns its bounding box.\n",
    "  \"\"\"\n",
    "  state = []\n",
    "  track_frame = cv2.inRange(frame.copy(), (0, 0, 140), (60, 60, 255))\n",
    "  track_frame = cv2.dilate(track_frame, np.ones((39,39), np.uint8))\n",
    "  track_frame = cv2.erode(track_frame, np.ones((29,29), np.uint8))\n",
    "  \n",
    "  contour = cv2.findContours(track_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  contour = imutils.grab_contours(contour)\n",
    "  if len(contour)>0:\n",
    "    c = max(contour, key=cv2.contourArea)\n",
    "    (cent_x, cent_y), radius = cv2.minEnclosingCircle(c)\n",
    "    cent_x, cent_y, radius = int(cent_x),int(cent_y), int(radius)\n",
    "    state.append((cent_x-radius, cent_y-radius, 2*radius, 2*radius))\n",
    "    if (4*radius*radius)<1000:\n",
    "      state = []\n",
    "  return state\n",
    "\n",
    "\n",
    "def create_tracker(tracker_type='KCF'):\n",
    "  if tracker_type == 'BOOSTING':\n",
    "      tracker = cv2.TrackerBoosting_create()\n",
    "  elif tracker_type == 'MIL':\n",
    "      tracker = cv2.TrackerMIL_create()\n",
    "  elif tracker_type == 'KCF':\n",
    "      tracker = cv2.TrackerKCF_create()\n",
    "  elif tracker_type == 'TLD':\n",
    "      tracker = cv2.TrackerTLD_create()\n",
    "  elif tracker_type == 'MEDIANFLOW':\n",
    "      tracker = cv2.TrackerMedianFlow_create()\n",
    "  elif tracker_type == 'GOTURN':\n",
    "      tracker = cv2.TrackerGOTURN_create()\n",
    "  elif tracker_type == 'MOSSE':\n",
    "      tracker = cv2.TrackerMOSSE_create()\n",
    "  elif tracker_type == \"CSRT\":\n",
    "      tracker = cv2.TrackerCSRT_create()\n",
    "  else:\n",
    "      print(\"No valid tracker type given! Using type 'KCF'.\")\n",
    "      tracker = cv2.TrackerKCF_create()\n",
    "\n",
    "  return tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-288FlkJg0a"
   },
   "source": [
    "## Detecting and Tracking of a Single Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ry5QPb0HJnYd"
   },
   "outputs": [],
   "source": [
    "def track(video, frame, bbox, output_writer, num_frames=5):\n",
    "  \"\"\"\n",
    "  Tracks given object for num_frames frames, draws a bounding box around the object\n",
    "  and writes those frames to an output.\n",
    "  \"\"\"\n",
    "  \n",
    "  # Create and initialize a tracker using the function from above\n",
    "  # See documentation for cv::Tracker to see how to initialize it\n",
    "  < your code here >\n",
    "\n",
    "  for i in range(num_frames):\n",
    "    ok, frame = video.read()\n",
    "    if not ok:\n",
    "        print(\"[function 'track'] Error reading frame from video!\")\n",
    "        break\n",
    "    \n",
    "    # Update the tracker with the current frame\n",
    "    # If the tracking was successful, draw a rectangle/bounding box around the object\n",
    "    # If not successful, draw text on the frame indicating a tracking error\n",
    "    < your code here>\n",
    "\n",
    "    # Display the frame (in the output below or into a video file)\n",
    "    show_in_row([frame])\n",
    "    # output_writer.write(frame)\n",
    "\n",
    "\n",
    "def detect_object_and_track(path, output_writer, num_frames):\n",
    "  \"\"\"\n",
    "  Opens a video, tries to detect a large, red object and then tries to track it\n",
    "  for the next num_frames frames and draw a bounding box around it.\n",
    "  \"\"\"\n",
    "  video = cv2.VideoCapture(path)\n",
    "\n",
    "  try:\n",
    "    while(True):\n",
    "      ret, frame = video.read()\n",
    "      if not ret:\n",
    "        print(\"[function 'detect_object_and_track'] Error reading frame from video!\")\n",
    "        video.release()\n",
    "        break\n",
    "\n",
    "      # Detect a red object. If found, draw a bounding box around the object,\n",
    "      # display or write the frame (image) with the bounding box to a video\n",
    "      # and track the object for the next num_frames frames.\n",
    "      # If it wasn't found, just display or write the unchanged image.\n",
    "      < your code here >\n",
    "\n",
    "  except KeyboardInterrupt:\n",
    "    video.release()\n",
    "\n",
    "out = cv2.VideoWriter('output_single.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 30, (640, 360))\n",
    "detect_object_and_track('vid.mp4', out, 5)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1vljdiu9uL23"
   },
   "source": [
    "## Detect (via SSD) and Track Multiple Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 130783,
     "status": "ok",
     "timestamp": 1587395907212,
     "user": {
      "displayName": "Marbin Eselmann",
      "photoUrl": "",
      "userId": "00197501137516660733"
     },
     "user_tz": -180
    },
    "id": "wKIy3JsVuYNz",
    "outputId": "1afe3ffb-3b5d-432a-a821-ba288f35939b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Easy to use car detector that takes an image and ouputs a list of bounding boxes\n",
    "class CarDetector():\n",
    "  def __init__(self):\n",
    "    module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\"\n",
    "    self.detector = hub.load(module_handle).signatures['default']\n",
    "  \n",
    "  def filter_boxes(self, image, boxes, class_names, scores, max_boxes=10, min_score=0.6, class_of_interest='Car'):\n",
    "    im_height, im_width = image.shape[:2]\n",
    "    state=[]\n",
    "\n",
    "    for i in range(min(boxes.shape[0], max_boxes)):\n",
    "      if scores[i] >= min_score and class_names[i].decode(\"ascii\")==class_of_interest:\n",
    "        [ymin, xmin, ymax, xmax] = boxes[i]\n",
    "        (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "        left, right, top, bottom = min(left, right), max(left, right), min(top, bottom), max(top, bottom)\n",
    "        left, right, top, bottom  = int(left), int(right), int(top), int(bottom) \n",
    "        state.append((left, top, right-left, bottom-top))\n",
    "    return state\n",
    "\n",
    "  def detect(self, img):\n",
    "    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "    result = self.detector(converted_img)\n",
    "\n",
    "    result = {key:value.numpy() for key,value in result.items()}\n",
    "    bbox = self.filter_boxes(img, result[\"detection_boxes\"],\n",
    "        result[\"detection_class_entities\"], result[\"detection_scores\"])\n",
    "    return bbox\n",
    "\n",
    "\n",
    "def track_multiple(video, frame, bboxes, output_writer, num_frames=5):\n",
    "  \"\"\"\n",
    "  Tracks object for num_frames frames\n",
    "  \"\"\"\n",
    "  \n",
    "  # Create a MultiTracker and for each bounding box, add a tracker to it\n",
    "  # See the documentation for cv::MultiTracker to find the necessary functions\n",
    "  < your code here >\n",
    "\n",
    "  for i in range(num_frames):\n",
    "    ok, frame = video.read()\n",
    "    if not ok:\n",
    "        break\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # Detector uses RGB, so we will work in this space\n",
    "    \n",
    "    # Feed the tracker with a new image and draw a bounding box for each\n",
    "    # tracked object onto the frame\n",
    "    < your code here >\n",
    "\n",
    "    # show_in_row([frame])\n",
    "    output_writer.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)) # Converting back to BGR, to write correct colors\n",
    "\n",
    "\n",
    "\n",
    "def detect_object_and_track(path, output_writer, num_frames=300, start_frame=0):\n",
    "  video = cv2.VideoCapture(path)\n",
    "  video.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "  ok, frame = video.read()\n",
    "\n",
    "  try:\n",
    "   while video.get(cv2.CAP_PROP_POS_FRAMES) < start_frame + num_frames:\n",
    "      ret, frame = video.read()\n",
    "      if not ret:\n",
    "        video.release()\n",
    "        break\n",
    "      frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "      state = car_detect.detect(frame)\n",
    "      # If we found objects, draw a bounding box around each detected object,\n",
    "      # display or write the resulting image and then track all found objects.\n",
    "      # If nothing was found, display or draw the unchanged image.\n",
    "      # REMEMBER TO CONVERT BACK TO BGR if you are writing to a video file!\n",
    "      < your code here >\n",
    "      \n",
    "  except KeyboardInterrupt:\n",
    "    video.release()\n",
    "\n",
    "out = cv2.VideoWriter('output_multiple.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 25, (640, 360))\n",
    "car_detect = CarDetector()\n",
    "detect_object_and_track(\"cars.mp4\", out, 750, 4950) # start video at 3 min 18 sec, run for 750 frames\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab13.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
